{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98f74184-0976-4dc8-8e5a-235b14fa4e2c",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "376a320b672c7b44e2effcf32effc572",
     "grade": false,
     "grade_id": "cell-f8987996be9f1238",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Utilización del servicio de alquiler de bicicletas en Toronto en el año 2018\n",
    "\n",
    "### Disponible en Kaggle en el siguiente enlace (que NO debe usarse para el ejercicio, sino los CSV que se adjuntaron al email):\n",
    "https://www.kaggle.com/jackywang529/toronto-bikeshare-data\n",
    "\n",
    "\n",
    "El propósito de este análisis es utilizar los conjuntos de datos trimestrales del año 2018 de la empresa de alquiler de bicicletas en Toronto. Se trata de *cuatro* conjuntos de datos separados, que incluyen entre 178.559 y 822.536 observaciones, siempre con nueve variables. Cada fila representa un viaje realizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2675ef05-1aa6-4441-80ae-6784635c35c9",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a6b4dc108ddf890c659e33701965428",
     "grade": false,
     "grade_id": "cell-f74d7bfd01811789",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Variables y significado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df77f48d-d0bc-4236-af09-069357021487",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0cb790eed3719dc8d6cfd639c9176b4a",
     "grade": false,
     "grade_id": "cell-9cfb34982bd4eb04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Las variables utilizadas para describir cada viaje son:\n",
    "\n",
    "* trip_id – identificador global del viaje\n",
    "* trip_duration_seconds – duración del viaje en segundos\n",
    "* from_station_id – identificador numérico de la estación de origen\n",
    "* trip_start_time – instante (timestamp) en el que se inició el viaje\n",
    "* from_station_name – nombre de la intersección más cercana a la estación origen\n",
    "* trip_stop_time – instante (timestamp) en el que finalizó el viaje\n",
    "* to_station_id – identificador numérico de la estación de destino\n",
    "* to_station_name – nombre de la intersección más cercana a la estación de destino\n",
    "* user_type – tipo de usuario (indicador binario): miembro registrado con cuota anual / usuario ocasional no registrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0ea03b0-953d-4a24-8a89-89dd268a701e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Nombre completo del alumno: SONIA TRABADO AGUILERA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b412da1e-62f5-4a09-a189-2730798357db",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7793cb7f9290ca23e841c9ede328bc84",
     "grade": false,
     "grade_id": "cell-b4f9c37a2b92d2e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# INSTRUCCIONES\n",
    "\n",
    "En cada celda debes responder a la pregunta formulada, asegurándote de que el resultado queda guardado en la(s) variable(s) que por defecto vienen inicializadas a `None`. No se necesita usar variables intermedias, pero puedes hacerlo siempre que el resultado final del cálculo quede guardado exactamente en la variable que venía inicializada a None (debes reemplazar None por la secuencia de transformaciones necesarias, pero nunca cambiar el nombre de esa variable). \n",
    "\n",
    "**No olvides borrar la línea *raise NotImplementedError()* de cada celda cuando hayas completado la solución de esa celda y quieras probarla**.\n",
    "\n",
    "Después de cada celda evaluable verás una celda con código. Ejecútala (no modifiques su código) y te dirá si tu solución es correcta o no. En caso de ser correcta, se ejecutará correctamente y no mostrará nada, pero si no lo es mostrará un error. Además de esas pruebas, se realizarán algunas más (ocultas) a la hora de puntuar el ejercicio, pero evaluar dicha celda es un indicador bastante fiable acerca de si realmente has implementado la solución correcta o no. Asegúrate de que, al menos, todas las celdas indican que el código es correcto antes de enviar el notebook terminado.\n",
    "\n",
    "\n",
    "**Nunca se debe redondear ninguna cantidad si no lo pide explícitamente el enunciado**\n",
    "\n",
    "### Cada solución debe escribirse obligatoriamente en la celda habilitada para ello. Cualquier celda adicional que se haya creado durante el desarrollo deberá ser eliminada.\n",
    "\n",
    "Si necesitas crear celdas auxiliares durante el desarrollo, puedes hacerlo pero debes asegurarte de borrarlas antes de entregar el notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "362c272c-d258-4fd2-8e4e-8e7eb9781792",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8bae739df33929bae8d756987e80caf8",
     "grade": false,
     "grade_id": "cell-69ec0993eeaff3ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Sobre los cuatro datasets anteriores (Bike Share Toronto Ridership_Q1 2018.csv hasta Q4) se pide:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f5efbf4-1e83-4ae2-b1ad-513b2e886b18",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**(1 punto)** Ejercicio 1\n",
    "\n",
    "* Leer por separado cada uno de ellos (sin cachear), tratando de que Spark infiera el tipo de dato de cada columna, y **unirlos en un solo DF** que tampoco debe ser cacheada todavía, ya que en el siguiente paso aún realizaremos otro pre-procesamiento.\n",
    "* Los cuatro contienen las mismas columnas por lo que no habrá problemas para utilizar la operación `union` encadenada tres veces para crear el DF final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b35408ea-d078-41f5-9f0d-a97e23e2eae2",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44717972bf7cac300a5ad876d9fd6632",
     "grade": false,
     "grade_id": "read_csv",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# LÍNEA EVALUABLE, NO RENOMBRAR LAS VARIABLES\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Crear una sesión de Spark\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Leer los archivos CSV\n",
    "tripsQ1 = spark.read.option(\"inferSchema\", \"true\").csv(\"abfss://datos@mastersta001sta.dfs.core.windows.net/Bike Share Toronto Ridership_Q1 2018.csv\", header=True)\n",
    "tripsQ2 = spark.read.option(\"inferSchema\", \"true\").csv(\"abfss://datos@mastersta001sta.dfs.core.windows.net/Bike Share Toronto Ridership_Q2 2018.csv\", header=True)\n",
    "tripsQ3 = spark.read.option(\"inferSchema\", \"true\").csv(\"abfss://datos@mastersta001sta.dfs.core.windows.net/Bike Share Toronto Ridership_Q3 2018.csv\", header=True)\n",
    "tripsQ4 = spark.read.option(\"inferSchema\", \"true\").csv(\"abfss://datos@mastersta001sta.dfs.core.windows.net/Bike Share Toronto Ridership_Q4 2018.csv\", header=True)\n",
    "\n",
    "tripsTorontoRawDF = tripsQ1.union(tripsQ2).union(tripsQ3).union(tripsQ4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cadf09c5-0dd1-4591-9f0d-74ca639d5b0a",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e6fa646bfe97c4d7d321099133d99e4",
     "grade": true,
     "grade_id": "read_csv_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "assert(tripsTorontoRawDF.count() == 1922955)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46b26788-db9c-4234-8643-7704efeb5fb8",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6eb33253c64dbd7870725e3e6d6a8e0f",
     "grade": false,
     "grade_id": "cell-b90f5b934eda250e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(1 punto)** Ejercicio 2\n",
    "\n",
    "* Las columnas `trip_start_time` y `trip_stop_time` son en realidad instantes de tiempo que Spark debería procesar como timestamp. Reemplaza **ambas columnas** por su versión convertida a timestamp, utilizando `withColumn` y donde el nuevo valor de la columna viene dado por el siguiente código:\n",
    "        F.from_unixtime(F.unix_timestamp('nombreColumna', 'M/d/yyyy H:mm')).cast(\"timestamp\"))\n",
    "El DF resultante debe ser almacenado en la variable `tripsTorontoDF`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37bdbe5c-f3d2-4f41-aa8a-fbd64fc3b36e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+-------------------+\n",
      "|              dt|              _2|             times2|\n",
      "+----------------+----------------+-------------------+\n",
      "|01/01/2018 00:47|01/01/2018 00:52|2018-01-01 00:47:00|\n",
      "+----------------+----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Crear DataFrame de ejemplo con fechas rellenadas con ceros a la izquierda\n",
    "time_df = spark.createDataFrame([('01/01/2018 00:47', '01/01/2018 00:52')], ['dt'])\n",
    "\n",
    "# Convertir la columna de tiempo a timestamp\n",
    "time_df = time_df.withColumn(\"times2\", from_unixtime(unix_timestamp(col(\"dt\"), 'MM/dd/yyyy HH:mm')).cast(\"timestamp\"))\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "time_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd1b3ca2-17ea-4370-8505-02ab0782158e",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9129c1d06eef70a5b6922585902dfa36",
     "grade": false,
     "grade_id": "convert_timestamp",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+\n",
      "|trip_id|trip_start_time|\n",
      "+-------+---------------+\n",
      "|2383653|  1/1/2018 1:07|\n",
      "+-------+---------------+\n",
      "\n",
      "+-------+-------------------+\n",
      "|trip_id|    trip_start_time|\n",
      "+-------+-------------------+\n",
      "|2383648|2018-01-01 00:47:00|\n",
      "|2383649|2018-01-01 00:52:00|\n",
      "|2383650|2018-01-01 00:55:00|\n",
      "|2383651|2018-01-01 00:57:00|\n",
      "|2383652|2018-01-01 01:00:00|\n",
      "|2383653|2018-01-01 01:07:00|\n",
      "|2383654|2018-01-01 01:33:00|\n",
      "|2383655|2018-01-01 01:34:00|\n",
      "|2383657|2018-01-01 01:37:00|\n",
      "|2383658|2018-01-01 01:38:00|\n",
      "|2383659|2018-01-01 01:39:00|\n",
      "|2383660|2018-01-01 01:39:00|\n",
      "|2383661|2018-01-01 01:49:00|\n",
      "|2383662|2018-01-01 01:57:00|\n",
      "|2383663|2018-01-01 02:06:00|\n",
      "|2383664|2018-01-01 02:25:00|\n",
      "|2383665|2018-01-01 02:29:00|\n",
      "|2383666|2018-01-01 02:30:00|\n",
      "|2383667|2018-01-01 02:45:00|\n",
      "|2383668|2018-01-01 02:53:00|\n",
      "+-------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "# LÍNEAS EVALUABLES, NO RENOMBRAR LAS VARIABLES\n",
    "tripsTorontoDF = tripsTorontoRawDF.withColumn(\"trip_start_time\", F.to_timestamp(F.col('trip_start_time'), 'M/d/yyyy H:mm')) \\\n",
    "    .withColumn(\"trip_stop_time\", F.to_timestamp(F.col('trip_stop_time'), 'M/d/yyyy H:mm'))\n",
    "\n",
    "# Mostrar las columnas 'trip_id' y 'trip_start_time' del DataFrame original donde 'trip_id' es igual a 2383653\n",
    "tripsTorontoRawDF.select(\"trip_id\", \"trip_start_time\").where(F.col(\"trip_id\") == 2383653).show()\n",
    "\n",
    "# Mostrar las columnas 'trip_id' y 'trip_start_time' del DataFrame actualizado\n",
    "tripsTorontoDF.select(\"trip_id\", \"trip_start_time\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed143b8d-e773-4fe2-b3f4-fd4137ad9395",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ebd685fd8c8fcd5062ecd1c29adcd4b",
     "grade": true,
     "grade_id": "convert_timestamp_tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "typesDict = dict(tripsTorontoDF.dtypes)\n",
    "assert(typesDict[\"trip_start_time\"] == \"timestamp\") \n",
    "assert(typesDict[\"trip_stop_time\"] == \"timestamp\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c659521b-274e-4f99-b878-1517473f5b14",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d11d72889323abc3fa6626ed1da257f",
     "grade": false,
     "grade_id": "cell-fc88821f19453a51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(1 punto)** Ejercicio 3\n",
    "\n",
    "Partiendo de `tripsTorontoDF`, realizar las siguientes transformaciones encadenadas en este orden para crear un nuevo DF:\n",
    "* Primero, debemos quedarnos solamente con las filas donde `trip_start_time` no sea null.\n",
    "* Sobre el DF resultado de lo anterior, añadir una columna adicional **Mes** y con el mes representado en **trip_start_time**. Dicha columna será de tipo entero y se puede obtener usando `withColumn` con la función `F.month(\"colName\")`, que recibe un nombre de columna y devuelve un objeto columna de enteros que van de 1 a 12. \n",
    "* Encadenar esta transformación con otra en la que la columna **Mes** sea reemplazada por su traducción a  cadena de caracteres de 3 letras, siendo la correspondencia 1: Ene, 2: Feb, 3: Mar, 4: Abr, 5: May, 6: Jun, 7: Jul, 8: Ago, 9: Sep, 10: Oct, 11: Nov, 12: Dic.\n",
    "* Finalmente, añadir una nueva columna **Hora** que contenga la hora de inicio del viaje, aplicando `withColumn` con la función `F.hour(\"colName\")` que recibe un nombre de columna y recibe un objeto columna de enteros de 0 a 23.\n",
    "* El DF resultante de todas estas transformaciones debe guardarse en la variable `tripsTorontoTimesDF`, que por tanto tendrá 2 columnas más que el DF original `tripsTorontoDF`, y que debe quedar **cacheado**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f75e9f9-2325-46c0-8495-90dee10b7520",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2aa969fc933e984b995caf9a857feede",
     "grade": false,
     "grade_id": "renombrar_mes_hora",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+---+----+\n",
      "|trip_id|    trip_start_time|Mes|Hora|\n",
      "+-------+-------------------+---+----+\n",
      "|2383648|2018-01-01 00:47:00|Ene|   0|\n",
      "|2383649|2018-01-01 00:52:00|Ene|   0|\n",
      "|2383650|2018-01-01 00:55:00|Ene|   0|\n",
      "|2383651|2018-01-01 00:57:00|Ene|   0|\n",
      "|2383652|2018-01-01 01:00:00|Ene|   1|\n",
      "|2383653|2018-01-01 01:07:00|Ene|   1|\n",
      "|2383654|2018-01-01 01:33:00|Ene|   1|\n",
      "|2383655|2018-01-01 01:34:00|Ene|   1|\n",
      "|2383657|2018-01-01 01:37:00|Ene|   1|\n",
      "|2383658|2018-01-01 01:38:00|Ene|   1|\n",
      "|2383659|2018-01-01 01:39:00|Ene|   1|\n",
      "|2383660|2018-01-01 01:39:00|Ene|   1|\n",
      "|2383661|2018-01-01 01:49:00|Ene|   1|\n",
      "|2383662|2018-01-01 01:57:00|Ene|   1|\n",
      "|2383663|2018-01-01 02:06:00|Ene|   2|\n",
      "|2383664|2018-01-01 02:25:00|Ene|   2|\n",
      "|2383665|2018-01-01 02:29:00|Ene|   2|\n",
      "|2383666|2018-01-01 02:30:00|Ene|   2|\n",
      "|2383667|2018-01-01 02:45:00|Ene|   2|\n",
      "|2383668|2018-01-01 02:53:00|Ene|   2|\n",
      "+-------+-------------------+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LÍNEA EVALUABLE, NO RENOMBRAR VARIABLES\n",
    "from pyspark.sql.types import *\n",
    "# Asegurándonos de que 'trip_start_time' no es nulo\n",
    "tripsTorontoTimesDF = tripsTorontoDF.where(F.col(\"trip_start_time\").isNotNull())\n",
    "\n",
    "# Creando una nueva columna 'Mes' a partir de 'trip_start_time'\n",
    "tripsTorontoTimesDF = tripsTorontoTimesDF.withColumn(\"Mes\", F.month(\"trip_start_time\"))\n",
    "\n",
    "# Reemplazando los números de los meses por sus nombres\n",
    "tripsTorontoTimesDF = tripsTorontoTimesDF.withColumn(\"Mes\", \n",
    "                                                     when(F.col(\"Mes\") == 1, \"Ene\")\n",
    "                                                     .when(F.col(\"Mes\") == 2, \"Feb\")\n",
    "                                                     .when(F.col(\"Mes\") == 3, \"Mar\")\n",
    "                                                     .when(F.col(\"Mes\") == 4, \"Abr\")\n",
    "                                                     .when(F.col(\"Mes\") == 5, \"May\")\n",
    "                                                     .when(F.col(\"Mes\") == 6, \"Jun\")\n",
    "                                                     .when(F.col(\"Mes\") == 7, \"Jul\")\n",
    "                                                     .when(F.col(\"Mes\") == 8, \"Ago\")\n",
    "                                                     .when(F.col(\"Mes\") == 9, \"Sep\")\n",
    "                                                     .when(F.col(\"Mes\") == 10, \"Oct\")\n",
    "                                                     .when(F.col(\"Mes\") == 11, \"Nov\")\n",
    "                                                     .when(F.col(\"Mes\") == 12, \"Dic\"))\n",
    "\n",
    "# Creando una nueva columna 'Hora' a partir de 'trip_start_time'\n",
    "tripsTorontoTimesDF = tripsTorontoTimesDF.withColumn(\"Hora\", hour(\"trip_start_time\"))\n",
    "\n",
    "# Almacenando el DataFrame en caché para mejorar el rendimiento\n",
    "tripsTorontoTimesDF.cache()\n",
    "\n",
    "# Mostrando las columnas seleccionadas del DataFrame\n",
    "tripsTorontoTimesDF.select(\"trip_id\", \"trip_start_time\", \"Mes\", \"Hora\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b4da6eb-6ff6-4726-bbdb-1e7a8936784d",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b60aed54e852d77c7fa8482a4c34379c",
     "grade": true,
     "grade_id": "renombrar_mes_hora_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tripsPerMonth = tripsTorontoTimesDF.groupBy(\"Mes\").count().sort(\"Mes\").collect()\n",
    "assert(tripsPerMonth[0][\"count\"] == 94783)\n",
    "assert(tripsPerMonth[1][\"count\"] == 281219)\n",
    "assert(tripsPerMonth[2][\"count\"] == 83324)\n",
    "assert(tripsPerMonth[3][\"count\"] == 43859)\n",
    "assert(tripsPerMonth[4][\"count\"] == 49731)\n",
    "assert(tripsPerMonth[5][\"count\"] == 286316)\n",
    "assert(tripsPerMonth[6][\"count\"] == 250837)\n",
    "assert((tripsPerMonth[7][\"count\"] == 84959) | (tripsPerMonth[7][\"count\"] == 84969))\n",
    "assert(tripsPerMonth[8][\"count\"] == 212750)\n",
    "assert(tripsPerMonth[9][\"count\"] == 104287)\n",
    "assert(tripsPerMonth[10][\"count\"] == 175879)\n",
    "assert(tripsPerMonth[11][\"count\"] == 255001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "794454e9-7471-40f1-9f4e-27f1bea6fd81",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f98c8387ad8a683f0ea2f1c6e441e07a",
     "grade": false,
     "grade_id": "cell-a71a6b17b1e0d613",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(1 punto)** Ejercicio 4\n",
    "\n",
    "* Partiendo de `tripsTorontoTimesDF`, crear un nuevo DataFrame con **tantas filas como horas tiene el día, y tantas columnas como meses del año** de manera que cada celda indique el **número de viajes** que comenzaron a esa hora en ese mes del año. Guardar el resultado en la variable `tripsPerMonthAndHourDF`, cuyas filas deben quedar ordenadas en base a la hora (de 0 a 23), y cuyas columnas deben estar también ordenadas desde `\"Ene\"` a `\"Dic\"`, con `\"Hora\"` como primera columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05893093-818b-472b-8981-2969741a0be5",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "416095b927a3c16ca9843df1228e43d3",
     "grade": false,
     "grade_id": "numero_categorias",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+----+\n",
      "|Hora| Ene| Feb|  Mar|  Abr|  May|  Jun|  Jul|  Ago|  Sep|  Oct|  Nov| Dic|\n",
      "+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+----+\n",
      "|   0| 425| 412|  689|  770| 1913| 2859| 3418| 2912| 2623| 1419|  888| 782|\n",
      "|   1| 266| 308|  434|  493| 1180| 1725| 1991| 1831| 1689|  943|  637| 525|\n",
      "|   2| 201| 183|  318|  374|  804| 1274| 1356| 1360| 1344|  684|  442| 417|\n",
      "|   3|  91| 101|  156|  130|  361|  587|  646|  595|  632|  245|  211| 164|\n",
      "|   4|  49|  56|  133|  114|  227|  463|  494|  504|  467|  264|  253| 187|\n",
      "|   5| 198| 226|  348|  381|  627|  877| 1121| 1110| 1032|  860|  569| 373|\n",
      "|   6| 603| 668|  995| 1092| 2043| 2802| 3232| 3088| 2800| 2373| 1745|1082|\n",
      "|   7|1742|2011| 3303| 3436| 6626| 8209| 8978| 8146| 8130| 6217| 4286|2914|\n",
      "|   8|5001|5199| 8682| 9825|17855|20602|23931|22475|21216|17825|11720|8293|\n",
      "|   9|3728|3769| 6497| 6790|12063|14044|16089|14978|14710|12381| 8314|6287|\n",
      "|  10|1975|2017| 3557| 3624| 7830| 8641|10195|10306| 9873| 6935| 4100|3634|\n",
      "|  11|1873|1893| 3747| 3865| 9278|10121|11823|12570|11549| 7437| 4444|3900|\n",
      "|  12|2259|2386| 4548| 4761|11427|12701|14796|15539|14362| 9308| 5445|4696|\n",
      "|  13|2117|2334| 4379| 4878|12117|13189|15492|16393|14755| 9089| 5296|4908|\n",
      "|  14|2002|2269| 4271| 4735|11909|13186|14915|15775|14261| 8573| 4910|4786|\n",
      "|  15|2483|2855| 4933| 5690|13518|14495|16429|16923|16075| 9899| 5835|5362|\n",
      "|  16|3936|4482| 7333| 8475|18306|19759|22815|22772|21378|14895| 8682|7146|\n",
      "|  17|4981|6320|10064|11456|25144|28216|32028|31734|29342|21593|11944|9043|\n",
      "|  18|3314|4383| 7332| 8440|19013|22257|25347|25571|22663|16048| 8319|6396|\n",
      "|  19|2147|2556| 4556| 5487|14104|17638|19146|18937|15996| 9865| 5228|4046|\n",
      "|  20|1580|1913| 3225| 3750|10061|13930|15567|14268|11166| 6886| 3868|3024|\n",
      "|  21|1275|1511| 2549| 2835| 7194|10429|12081|10314| 8459| 5558| 3164|2311|\n",
      "|  22| 934|1158| 1804| 2049| 5449| 7558| 8365| 7477| 6260| 3909| 2347|1840|\n",
      "|  23| 679| 721| 1116| 1333| 3701| 5275| 6061| 5641| 4219| 2673| 1640|1208|\n",
      "+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LÍNEA EVALUABLE, NO RENOMBRAR VARIABLES\n",
    "# Seleccionar las columnas 'Hora' y 'Mes', agrupar por 'Hora', pivotar por 'Mes' y contar el número de registros\n",
    "tripsPerMonthAndHourDF = tripsTorontoTimesDF.select(\"Hora\", \"Mes\")\\\n",
    "                                            .groupBy(\"Hora\")\\\n",
    "                                            .pivot(\"Mes\", ['Ene','Feb','Mar','Abr','May','Jun','Jul','Ago', 'Sep', 'Oct', 'Nov', 'Dic'])\\\n",
    "                                            .agg(count(\"*\"))\\\n",
    "                                            .orderBy(\"Hora\")\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "tripsPerMonthAndHourDF.show(24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "427c9310-7c5f-4b43-a8da-e712bbfcfbe4",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d64ff89bcbd46871e937ae34db834496",
     "grade": true,
     "grade_id": "numero_categorias_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(len(tripsPerMonthAndHourDF.columns) == 13)\n",
    "assert(tripsPerMonthAndHourDF.columns[0] == \"Hora\")\n",
    "assert(tripsPerMonthAndHourDF.columns[12] == \"Dic\")\n",
    "assert(tripsPerMonthAndHourDF.count() == 24)\n",
    "todasHoras = tripsPerMonthAndHourDF.collect()\n",
    "assert((todasHoras[0][\"Hora\"] == 0) & (todasHoras[0][\"Dic\"]==782))\n",
    "assert((todasHoras[23][\"Hora\"] == 23) & (todasHoras[23][\"Dic\"]==1208))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce6a4948-db7a-48cd-baa4-0e6d133ae0a8",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d2b0a3fb505c65793ee15bf17e87e87",
     "grade": false,
     "grade_id": "cell-c5ec05706eccd480",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(3 puntos)** Ejercicio 5. \n",
    "\n",
    "Partiendo de `tripsTorontoTimesDF` definido anteriormente, añadir las siguientes columnas:\n",
    "\n",
    "* Primero, tres columnas adicionales llamadas `dur_media`, `dur_min`, `dur_max` que contengan, respectivamente, **la duración media, mínima y máxima de los viajes que parten de esa misma estación de origen (from_station_id) a esa misma hora y en ese mismo mes del año**. Es decir, queremos una columna extra para que podamos tener, junto a cada viaje, información agregada de los viajes similares, entendidos como aquellos que salieron a la misma hora de la misma estación. **No se debe utilizar JOIN sino solo funciones de ventana**.\n",
    "* A continuación, otra columna adicional `diff_dur_porc` que contenga la diferencia, medida en porcentaje, entre la duración del viaje y la duración media de los viajes similares calculada en el apartado anterior. Dicha diferencia debe calcularse como la resta de la duración del viaje menos la duración media, dividida entre la duración media y multiplicada por 100. El resultado debe obtenerse aplicando operaciones aritméticas con columnas existentes, **sin utilizar `when`**.\n",
    "* El DF resultante con las 4 columnas nuevas que hemos añadido debe almacenarse en la variable `tripsTorontoExtraInfoDF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91937cb5-f069-4401-9876-d8a1f6b3b7fb",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "14773754aebd257287c3ab4a00b00379",
     "grade": false,
     "grade_id": "ventana",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---+----+-----------------+-------+-------+-------------------+\n",
      "|from_station_id|Mes|Hora|        dur_media|dur_min|dur_max|      diff_dur_porc|\n",
      "+---------------+---+----+-----------------+-------+-------+-------------------+\n",
      "|           7000|Abr|   2|            123.0|    123|    123|                0.0|\n",
      "|           7000|Abr|   9|485.8814814814815|    120|   1610| -20.76256974723298|\n",
      "|           7000|Abr|   9|485.8814814814815|    120|   1610|  -3.06278013232918|\n",
      "|           7000|Abr|   9|485.8814814814815|    120|   1610|  4.963868646522544|\n",
      "|           7000|Abr|   9|485.8814814814815|    120|   1610| 3.1115650821721457|\n",
      "|           7000|Abr|   9|485.8814814814815|    120|   1610| -13.35335548983139|\n",
      "|           7000|Abr|   9|485.8814814814815|    120|   1610|-15.823093575631923|\n",
      "|           7000|Abr|   9|485.8814814814815|    120|   1610| 2.9057535750221017|\n",
      "|           7000|Abr|   9|485.8814814814815|    120|   1610|-15.205659054181789|\n",
      "|           7000|Abr|   9|485.8814814814815|    120|   1610|-14.176601518431568|\n",
      "|           7000|Abr|   9|485.8814814814815|    120|   1610| 21.840412232826168|\n",
      "|           7000|Abr|   9|485.8814814814815|    120|   1610| 24.721773332926787|\n",
      "|           7000|Abr|   9|485.8814814814815|    120|   1610| 24.104338811476655|\n",
      "|           7000|Abr|   9|485.8814814814815|    120|   1610| -53.28078787693996|\n",
      "|           7000|Abr|   9|485.8814814814815|    120|   1610|-11.706863432631037|\n",
      "|           7000|Abr|   9|485.8814814814815|    120|   1610|-18.087020154282406|\n",
      "|           7000|Abr|   9|485.8814814814815|    120|   1610|-19.321889197182674|\n",
      "|           7000|Abr|   9|485.8814814814815|    120|   1610| 10.932402353873826|\n",
      "|           7000|Abr|   9|485.8814814814815|    120|   1610|  5.992926182272765|\n",
      "|           7000|Abr|   9|485.8814814814815|    120|   1610|-24.467176875933777|\n",
      "+---------------+---+----+-----------------+-------+-------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LÍNEA EVALUABLE, NO RENOMBRAR VARIABLES\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Crear una ventana particionada por 'from_station_id', 'Mes' y 'Hora'\n",
    "windowHoraMesEstacion = tripsTorontoTimesDF.withColumn(\"dur_media\", avg(\"trip_duration_seconds\").over(Window.partitionBy(\"from_station_id\", \"Mes\", \"Hora\")))\\\n",
    "                                            .withColumn(\"dur_min\", min(\"trip_duration_seconds\").over(Window.partitionBy(\"from_station_id\", \"Mes\", \"Hora\")))\\\n",
    "                                            .withColumn(\"dur_max\", max(\"trip_duration_seconds\").over(Window.partitionBy(\"from_station_id\", \"Mes\", \"Hora\")))\n",
    "\n",
    "# Calcular la diferencia porcentual entre la duración del viaje y la duración media\n",
    "tripsTorontoExtraInfoDF = windowHoraMesEstacion.withColumn(\"diff_dur_porc\", ((col(\"trip_duration_seconds\") - col(\"dur_media\")) / col(\"dur_media\")) * 100 )\n",
    "\n",
    "# Mostrar las columnas seleccionadas del DataFrame\n",
    "tripsTorontoExtraInfoDF.select(\"from_station_id\",\"Mes\", \"Hora\",\"dur_media\",\"dur_min\",\"dur_max\", \"diff_dur_porc\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00594704-1d8d-4b5c-b8d6-d3de76b0a83c",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "729b30b98cb70cb301206a9bce962a58",
     "grade": true,
     "grade_id": "ventana_test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "r = tripsTorontoExtraInfoDF.where(\"trip_id = '2970611'\").head()\n",
    "assert(r.dur_media - 783.366666667 < 0.001)\n",
    "assert(r.diff_dur_porc - 44.24918088591975 < 0.001)\n",
    "assert(r.dur_min == 167)\n",
    "assert(r.dur_max == 2333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aae6ad99-1301-4b16-9765-1cf283dd6a3d",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d49cdc97f3973ce93b2cfb164310714",
     "grade": false,
     "grade_id": "cell-9ebe35c4b4325269",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(3 puntos)** Ejercicio 6\n",
    "\n",
    "* Partiendo de `tripsTorontoTimesDF`, crear un **grafo** llamado `bikeGraph` utilizando como identificador de los vértices los identificadores de las estaciones. Construye primero un DF con todos los identificadores de las estaciones, simplemente seleccionando **from_station_id**, renombrando adecuadamente el nombre de columna. Puedes almacenar este DF en la variable `verticesDF`. También tendrás que renombrar las columnas **from_station_id** y **to_station_id** en el DF de aristas, para el que además deberás seleccionar solo dichas columnas y quitar las filas repetidas ya que solo necesitamos considerar una vez cada ruta (cada pareja de estación inicial y final). Puedes almacenar el resultado del renombramiento y la eliminación de repetidos en la variable `edgesDF`.\n",
    "* Una vez creado, aplica el algoritmo `pageRank` pasando como **ÚNICO** parámetro `maxIter = 5`, y **ningún parámetro más**. El algoritmo puede llegar a emplear más de 10 minutos. \n",
    "* Almacena el grafo devuelto por dicha función en la variable `pageRankGraph`, recupera el DF de sus vértices, ordénalo descendentemente en base a la columna `pagerank` y almacena el resultado en la variable `sortedPageRankGraphVerticesDF`\n",
    "* Obtén el identificador de la estación más relevante (con mayor valor de la métrica pageRank, que ocupará la primera fila tras la ordenación), y almacena dicho identificador en la variable `id_mas_relevante`.\n",
    "* Crea un nuevo DF de una sola fila y tres columnas llamadas `dur_media`, `dur_min` y `dur_max` con la duración **media, mínima y máxima** de los viajes de `tripsTorontoTimesDF` que **empiezan** en dicha estación (sin tener en cuenta distinción de horas o meses). **No debe usarse la función `withColumn` sino crear las columnas al vuelo con `select`**. Debe quedar almacenado en la variable `durEstMasRelevantesDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cdd2766-3d67-49cd-a785-918fd65239c5",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc1f29ab4015788d03e8e01be66ea200",
     "grade": false,
     "grade_id": "graph",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/spark/python/pyspark/sql/dataframe.py:175: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
      "  warnings.warn(\n",
      "/databricks/spark/python/pyspark/sql/dataframe.py:154: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
      "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
     ]
    }
   ],
   "source": [
    "# LÍNEA EVALUABLE, NO RENOMBRAR VARIABLES\n",
    "from pyspark.sql.functions import col\n",
    "from graphframes import GraphFrame\n",
    "\n",
    "# Establecer el directorio de checkpoint\n",
    "spark.sparkContext.setCheckpointDir(\"/tmp\")\n",
    "\n",
    "# Crear el DataFrame de vértices\n",
    "verticesDF = tripsTorontoTimesDF.select(col(\"from_station_id\").alias(\"id\")).distinct()\n",
    "\n",
    "# Crear el DataFrame de aristas\n",
    "edgesDF = tripsTorontoTimesDF.select(col(\"from_station_id\").alias(\"src\"), col(\"to_station_id\").alias(\"dst\")).distinct()\n",
    "\n",
    "# Crear el grafo\n",
    "bikeGraph = GraphFrame(verticesDF, edgesDF)\n",
    "\n",
    "# Aplicar el algoritmo PageRank\n",
    "pageRankGraph = bikeGraph.pageRank(maxIter=5)\n",
    "\n",
    "# Obtener el DataFrame de vértices ordenado por pagerank\n",
    "sortedPageRankGraphVerticesDF = pageRankGraph.vertices.orderBy(\"pagerank\", ascending=False)\n",
    "\n",
    "# Obtener el identificador de la estación más relevante\n",
    "id_mas_relevante = sortedPageRankGraphVerticesDF.first().id\n",
    "\n",
    "# Crear un nuevo DataFrame con la duración media, mínima y máxima de los viajes que empiezan en la estación más relevante\n",
    "durEstMasRelevantesDF = tripsTorontoTimesDF.filter(col(\"from_station_id\") == id_mas_relevante).selectExpr(\"avg(trip_duration_seconds) as dur_media\", \"min(trip_duration_seconds) as dur_min\", \"max(trip_duration_seconds) as dur_max\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03c52cdc-9d23-4459-847b-5f735bf7d450",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pagerank_value: 1.4427505264126441\n",
      "count_value: 1\n",
      "columns_length: 3\n",
      "dur_min_value: 61\n",
      "id_mas_relevante: 7060\n",
      "dur_media_value: 747.6957692082626\n",
      "dur_max_value: 35130\n"
     ]
    }
   ],
   "source": [
    "# Leer los parámetros\n",
    "pagerank_value = sortedPageRankGraphVerticesDF.head()[\"pagerank\"]\n",
    "count_value = durEstMasRelevantesDF.count()\n",
    "columns_length = len(durEstMasRelevantesDF.columns)\n",
    "rEstMasRelevantes = durEstMasRelevantesDF.head()\n",
    "dur_min_value = rEstMasRelevantes.dur_min\n",
    "dur_media_value = rEstMasRelevantes.dur_media\n",
    "dur_max_value = rEstMasRelevantes.dur_max\n",
    "\n",
    "# Imprimir los valores\n",
    "print(\"pagerank_value:\", pagerank_value)\n",
    "print(\"count_value:\", count_value)\n",
    "print(\"columns_length:\", columns_length)\n",
    "print(\"dur_min_value:\", dur_min_value)\n",
    "print(\"id_mas_relevante:\", id_mas_relevante)\n",
    "print(\"dur_media_value:\", dur_media_value)\n",
    "print(\"dur_max_value:\", dur_max_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f05ba3d6-fc7a-47dc-b641-11c240cbd61a",
     "showTitle": false,
     "title": ""
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cce36154f8b55fd019b7f285e1273958",
     "grade": true,
     "grade_id": "graph_tests",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(sortedPageRankGraphVerticesDF.head()[\"pagerank\"] - 1.4427 < 0.01)\n",
    "assert(durEstMasRelevantesDF.count() == 1)\n",
    "assert(len(durEstMasRelevantesDF.columns) == 3)\n",
    "rEstMasRelevantes = durEstMasRelevantesDF.head()\n",
    "assert(rEstMasRelevantes.dur_min == 61)\n",
    "assert(id_mas_relevante == 7060)\n",
    "assert(rEstMasRelevantes.dur_media - 747.6957692082626 < 0.001)\n",
    "assert(rEstMasRelevantes.dur_max == 35130)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Spark_m3",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
